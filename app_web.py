import json
import os
import re
import sys
import time
import uuid

import pandas as pd
import plotly.express as px
import streamlit as st
from langchain.chains.conversation.base import ConversationChain
from langchain.chains.conversational_retrieval.base import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
from langchain_community.document_loaders import TextLoader
from langchain_community.embeddings import HuggingFaceBgeEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent
from langchain_openai import ChatOpenAI
from langchain_text_splitters import RecursiveCharacterTextSplitter


os.environ["PYTHONIOENCODING"] = "utf-8"
os.environ["LANG"] = "C.UTF-8"
os.environ["LC_ALL"] = "C.UTF-8"

# è®¾ç½®ç³»ç»Ÿç¼–ç ä¸ºUTF-8
sys.stdout.reconfigure(encoding='utf-8')
sys.stderr.reconfigure(encoding='utf-8')


DF_AGENT_PROMPT_TEMPLATE = """
ä½ æ˜¯ä¸€ä¸ªæ•°æ®åˆ†æä¸“å®¶ï¼Œè¯·æ ¹æ®ä»¥ä¸‹æ•°æ®æ¡†å’Œç”¨æˆ·é—®é¢˜æä¾›å›ç­”ã€‚
å¿…é¡»ä¸¥æ ¼æŒ‰ç…§æŒ‡å®šæ ¼å¼å›å¤ï¼Œå¦åˆ™ç³»ç»Ÿå°†æ— æ³•è§£æï¼

**æ•°æ®æ¡†é¢„è§ˆ**:
{df_head}

**ç”¨æˆ·é—®é¢˜**: {query}

**å“åº”æ ¼å¼è¦æ±‚**:
- çº¯æ–‡æœ¬å›ç­” (å¦‚æœæ²¡æœ‰å¯è§†åŒ–éœ€æ±‚)
- æˆ–JSONæ ¼å¼ (å¦‚æœéœ€è¦å±•ç¤ºå›¾è¡¨):
{{
    "answer": "è¯¦ç»†çš„æ–‡æœ¬è§£é‡Šå’Œç»Ÿè®¡ç»“æœ:",
    "charts": [
        {{
            "type": "bar/line/pie/scatter/box/hist/area",
            "data": {{
                "columns": ["ç±»åˆ«A", "ç±»åˆ«B", ...],
                "data": [æ•°å€¼1, æ•°å€¼2, ...]
            }},
            "title": "å›¾è¡¨æ ‡é¢˜ (å¯é€‰)"
        }}
    ]
}}

**é‡è¦è§„åˆ™**:
1. å¤„ç†æ—¥æœŸæ—¶ä½¿ç”¨ 'ME' ä»£æ›¿ 'M'
2. å¦‚æœé‡åˆ°é”™è¯¯ï¼Œè¿”å› JSON æ ¼å¼çš„é”™è¯¯ä¿¡æ¯: {{"error": "é”™è¯¯æè¿°", "answer": "é”™è¯¯ä¿¡æ¯"}}
3. ä¸è¦åŒ…å«ä»»ä½•é¢å¤–è§£é‡Šæˆ–ä»£ç 
4. ç”¨æˆ·æ²¡æœ‰æ˜ç¡®è¦æ±‚å›¾è¡¨æ—¶ï¼Œè¯·ä»…è¿”å›æ–‡æœ¬ç­”æ¡ˆ
5. ä¸è¦è¿”å›æ•°æ®é¢„è§ˆå†…å®¹ï¼Œç”¨æˆ·å·²ç»åœ¨ä¸Šä¼ æ–‡ä»¶æ—¶çœ‹åˆ°æ•°æ®é¢„è§ˆ
6. å¯¹äºéœ€è¦ä»£ç è®¡ç®—çš„é—®é¢˜ï¼Œä½¿ç”¨ä»¥ä¸‹æ ¼å¼è°ƒç”¨å·¥å…·:
   Thought: åˆ†æé—®é¢˜å¹¶ç¡®å®šéœ€è¦ä½¿ç”¨çš„å·¥å…·
   Action: python_repl_ast
   Action Input: è¦æ‰§è¡Œçš„ Python ä»£ç ï¼ˆç¡®ä¿ä»£ç ç®€æ´å®Œæ•´ï¼‰
7. æ—¥æœŸå¤„ç†è¯·ä½¿ç”¨: pd.to_datetime(df['åˆ—å'], format='%Y-%m-%d')
8. ä¸è¦å°è¯•ç›´æ¥æ‰§è¡Œä»£ç ï¼Œå¿…é¡»é€šè¿‡å·¥å…·è°ƒç”¨
9. ç”Ÿæˆå›¾è¡¨æ—¶ï¼Œä¸è¦å°è¯•ä¿å­˜æ–‡ä»¶ï¼Œç›´æ¥è¿”å›å›¾è¡¨æ•°æ®
10. ç¡®ä¿æœˆä»½æ ¼å¼ç»Ÿä¸€ä¸º "YYYY-MM"ï¼ˆä¾‹å¦‚ "2020-03"ï¼‰
11. ç¡®ä¿æ¯ä¸ªæœˆä»½æ•°æ®å”¯ä¸€ï¼Œæ²¡æœ‰é‡å¤
12. å›¾è¡¨æ•°æ®æ ¼å¼å¿…é¡»ä¸¥æ ¼éµå¾ª:
    {{
        "type": "line/bar/pie/scatter/box/hist/area",
        "data": {{
            "columns": ["æœˆä»½", "é”€å”®é¢"],
            "data": [
                ["2020-01", 5409855],
                ["2020-02", 4608455],
                ...
            ]
        }},
        "title": "å›¾è¡¨æ ‡é¢˜ (å¯é€‰)"
    }}
13. ç¡®ä¿å›¾è¡¨æ•°æ®ä¸­æ¯ä¸ªæ•°ç»„å…ƒç´ éƒ½åŒ…å« 2 ä¸ªå€¼ï¼š[æœˆä»½, é”€å”®é¢]
14. æœˆä»½æ ¼å¼å¿…é¡»ç»Ÿä¸€ä¸º "YYYY-MM"ï¼ˆä¾‹å¦‚ "2020-03"ï¼‰
15. ç¡®ä¿æ¯ä¸ªæœˆä»½æ•°æ®å”¯ä¸€ï¼Œæ²¡æœ‰é‡å¤
16. ç¡®ä¿JSONæ ¼å¼æ­£ç¡®ï¼šé”®åä½¿ç”¨åŒå¼•å·ï¼Œå­—ç¬¦ä¸²å€¼ä½¿ç”¨åŒå¼•å·ï¼Œæ•°å€¼ä¸ä½¿ç”¨å¼•å·
"""

# æ–‡æœ¬ä»£ç†æç¤ºè¯æ¨¡æ¿
TEXT_AGENT_PROMPT_TEMPLATE = "ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„AIåŠ©æ‰‹ï¼Œç”¨ä¸­æ–‡å›ç­”é—®é¢˜"

# RAGä»£ç†æç¤ºè¯æ¨¡æ¿
RAG_AGENT_PROMPT_TEMPLATE = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®åˆ†æåŠ©æ‰‹ï¼Œè¯·æ ¹æ®ç”¨æˆ·çš„æ•°æ®æˆ–é—®é¢˜æä¾›å‡†ç¡®ã€è¯¦ç»†çš„å›ç­”"


def process_uploaded_file(uploaded_file):
    """å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶"""
    try:
        file_ext = uploaded_file.name.split(".")[-1].lower()
        session_id = str(uuid.uuid4())

        if file_ext in ["csv", "xlsx"]:
            if file_ext == "csv":
                st.session_state.df = pd.read_csv(uploaded_file)
                st.session_state.current_mode = "ğŸ“Š æ•°æ®åˆ†æ"
                st.success("CSVæ–‡ä»¶å·²æˆåŠŸåŠ è½½ï¼")
            else:  # xlsx
                excel_file = pd.ExcelFile(uploaded_file)
                sheet_names = excel_file.sheet_names

                if 'selected_sheet' not in st.session_state:
                    st.session_state.selected_sheet = sheet_names[0] if sheet_names else None

                if st.session_state.selected_sheet not in sheet_names:
                    st.session_state.selected_sheet = sheet_names[0] if sheet_names else None

                with st.sidebar:
                    st.subheader("Excelå·¥ä½œè¡¨é€‰æ‹©")
                    if sheet_names:
                        current_index = sheet_names.index(
                            st.session_state.selected_sheet) if st.session_state.selected_sheet in sheet_names else 0

                        selected_sheet = st.selectbox(
                            "è¯·é€‰æ‹©è¦åˆ†æçš„å·¥ä½œè¡¨",
                            sheet_names,
                            index=current_index
                        )

                        st.session_state.selected_sheet = selected_sheet
                        st.session_state.df = excel_file.parse(selected_sheet)
                        st.session_state.current_mode = "ğŸ“Š æ•°æ®åˆ†æ"
                        st.success(f"Excelæ–‡ä»¶çš„å·¥ä½œè¡¨ '{selected_sheet}' å·²æˆåŠŸåŠ è½½ï¼")
                    else:
                        st.error("Excelæ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å·¥ä½œè¡¨ï¼")

        elif file_ext == "txt":
            content = uploaded_file.read().decode("utf-8")
            file_path = f"{session_id}.txt"
            with open(file_path, "w", encoding="utf-8") as f:
                f.write(content)
            st.session_state.txt_content = content
            st.session_state.session_id = session_id
            st.session_state.is_new_file = True
            st.session_state.current_mode = "ğŸ“š æ–‡æ¡£é—®ç­”"
            st.success("æ–‡æœ¬æ–‡ä»¶å·²æˆåŠŸä¸Šä¼ ï¼")

        else:
            st.error("ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹ï¼")

    except Exception as e:
        st.error(f"æ–‡ä»¶å¤„ç†å¤±è´¥: {str(e)}")

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€ (æ·»åŠ current_modeå’Œselected_sheet)
def init_session_state():
    if 'current_session_messages' not in st.session_state:
        st.session_state.current_session_messages = [
            {'role': 'ai', 'content': 'ä½ å¥½ï¼Œæˆ‘æ˜¯ä½ çš„AIåŠ©æ‰‹ï¼Œè¯·é—®æœ‰ä»€ä¹ˆèƒ½å¸®åŠ©ä½ å—ï¼Ÿ'}]
    if 'history_sessions' not in st.session_state:
        st.session_state.history_sessions = []  # å­˜å‚¨æ‰€æœ‰å†å²ä¼šè¯
    if 'memory' not in st.session_state:
        st.session_state.memory = ConversationBufferMemory(return_messages=True)
    if 'df' not in st.session_state:
        st.session_state.df = None
    if 'txt_content' not in st.session_state:
        st.session_state.txt_content = None
    if 'viewing_history' not in st.session_state:
        st.session_state.viewing_history = False
    if 'current_session_index' not in st.session_state:
        st.session_state.current_session_index = None
    if 'session_id' not in st.session_state:
        st.session_state.session_id = uuid.uuid4().hex
    if 'is_new_file' not in st.session_state:
        st.session_state.is_new_file = True
    if 'API_KEY' not in st.session_state:
        st.session_state.API_KEY = ""
    if 'selected_model' not in st.session_state:
        st.session_state.selected_model = "gpt-4o-mini"
    if 'model_temperature' not in st.session_state:
        st.session_state.model_temperature = 0.7
    if 'model_max_length' not in st.session_state:
        st.session_state.model_max_length = 1000
    if 'system_prompt' not in st.session_state:
        # ä½¿ç”¨æç¤ºè¯
        st.session_state.system_prompt = TEXT_AGENT_PROMPT_TEMPLATE
    # æ·»åŠ current_modeå’Œselected_sheetçŠ¶æ€
    if 'current_mode' not in st.session_state:
        st.session_state.current_mode = "ğŸ’¬ èŠå¤©å¯¹è¯"
    if 'selected_sheet' not in st.session_state:
        st.session_state.selected_sheet = None

# ç”Ÿæˆç»Ÿè®¡å›¾è¡¨ (ä½¿ç”¨Plotly)
def create_chart(input_data, chart_type):
    """ç”Ÿæˆç»Ÿè®¡å›¾è¡¨"""
    try:
        # ç¡®ä¿æ ‡é¢˜ä½¿ç”¨UTF-8ç¼–ç 
        title = input_data.get("title", "é»˜è®¤å›¾è¡¨")
        if isinstance(title, str):
            title = title.encode('utf-8', 'ignore').decode('utf-8')

        # æ£€æŸ¥æ•°æ®æ ¼å¼ - å¤„ç†ä¸¤ç§æ ¼å¼
        if isinstance(input_data["data"][0], list):
            # å¤„ç†äºŒç»´æ•°ç»„æ ¼å¼ [["æœˆä»½", é”€å”®é¢], ...]
            df_data = pd.DataFrame(
                input_data["data"],
                columns=input_data["columns"]
            )
        else:
            # å¤„ç†ä¸€ç»´æ•°ç»„æ ¼å¼ ["æœˆä»½1", "æœˆä»½2", ...] å’Œ [é”€å”®é¢1, é”€å”®é¢2, ...]
            df_data = pd.DataFrame({
                input_data["columns"][0]: input_data["columns"],
                input_data["columns"][1]: input_data["data"]
            })

        # ç¡®ä¿æ‰€æœ‰åˆ—åéƒ½æ˜¯å­—ç¬¦ä¸²ç±»å‹
        df_data.columns = df_data.columns.astype(str)

        # === æ–°å¢ï¼šè¾“å‡ºå›¾è¡¨æ•°æ®åˆ°ç•Œé¢ ===
        st.subheader("ğŸ“Š å›¾è¡¨åŸå§‹æ•°æ®")
        st.dataframe(df_data, use_container_width=True)
        st.caption(f"æ•°æ®ç»´åº¦: {df_data.shape[0]} è¡Œ Ã— {df_data.shape[1]} åˆ—")
        # =============================

        # æ ¹æ®å›¾è¡¨ç±»å‹ç”Ÿæˆä¸åŒçš„å¯è§†åŒ–
        if chart_type == "bar":
            fig = px.bar(
                df_data,
                x=df_data.columns[0],
                y=df_data.columns[1],
                title=input_data.get("title", "æŸ±çŠ¶å›¾")
            )
            st.plotly_chart(fig, use_container_width=True)

        elif chart_type == "line":
            fig = px.line(
                df_data,
                x=df_data.columns[0],
                y=df_data.columns[1],
                title=input_data.get("title", "æŠ˜çº¿å›¾"),
                markers=True
            )
            st.plotly_chart(fig, use_container_width=True)

        elif chart_type == "pie":
            fig = px.pie(
                df_data,
                names=df_data.columns[0],
                values=df_data.columns[1],
                title=input_data.get("title", "é¥¼å›¾")
            )
            st.plotly_chart(fig, use_container_width=True)

        elif chart_type == "scatter":
            fig = px.scatter(
                df_data,
                x=df_data.columns[0],
                y=df_data.columns[1],
                title=input_data.get("title", "æ•£ç‚¹å›¾")
            )
            st.plotly_chart(fig, use_container_width=True)

        elif chart_type == "box":
            fig = px.box(
                df_data,
                y=df_data.columns[1],
                title=input_data.get("title", "ç®±çº¿å›¾")
            )
            st.plotly_chart(fig, use_container_width=True)

        elif chart_type == "hist":
            fig = px.histogram(
                df_data,
                x=df_data.columns[1],
                title=input_data.get("title", "ç›´æ–¹å›¾")
            )
            st.plotly_chart(fig, use_container_width=True)

        elif chart_type == "area":
            fig = px.area(
                df_data,
                x=df_data.columns[0],
                y=df_data.columns[1],
                title=input_data.get("title", "é¢ç§¯å›¾")
            )
            st.plotly_chart(fig, use_container_width=True)

        else:
            st.error(f"ä¸æ”¯æŒçš„å›¾è¡¨ç±»å‹: {chart_type}")

    except Exception as e:
        st.error(f"å›¾è¡¨ç”Ÿæˆå‡ºé”™ï¼š{e}")
        st.error(f"æ•°æ®æ ¼å¼: {input_data}")

# æ–‡æœ¬ä»£ç† - å¤„ç†æ— æ–‡ä»¶æƒ…å†µ
def text_agent(query):
    try:
        model = ChatOpenAI(
            api_key=st.session_state.API_KEY,
            base_url='https://twapi.openai-hk.com/v1',
            model=st.session_state.selected_model,
            temperature=st.session_state.model_temperature,
            max_tokens=st.session_state.model_max_length
        )
        chain = ConversationChain(llm=model, memory=st.session_state.memory)
        return chain.invoke({'input': query})['response']
    except Exception as e:
        st.error(f"æ–‡æœ¬å¤„ç†å‡ºé”™ï¼š{e}")
        return "æ— æ³•å¤„ç†æ‚¨çš„è¯·æ±‚ï¼Œè¯·æ£€æŸ¥é…ç½®æˆ–é‡è¯•ã€‚"

# æå–å›¾è¡¨æ•°æ®
def extract_chart_data(response_text):
    """å°è¯•ä»ä»£ç†å“åº”ä¸­æå–å›¾è¡¨æ•°æ®"""
    try:
        # æŸ¥æ‰¾JSONæ ¼å¼çš„å›¾è¡¨æ•°æ®
        if "```json" in response_text:
            json_str = response_text.split("```json")[1].split("```")[0].strip()
            return json.loads(json_str)
        # æŸ¥æ‰¾çº¯JSONæ ¼å¼
        elif response_text.strip().startswith("{") and response_text.strip().endswith("}"):
            return json.loads(response_text)
    except Exception as e:
        st.warning(f"å›¾è¡¨æ•°æ®è§£æå¤±è´¥: {str(e)}")
    return None

# å¢å¼ºJSONè§£æèƒ½åŠ›
def safe_json_parse(response_text):
    """å®‰å…¨åœ°è§£æå¯èƒ½åŒ…å«é¢å¤–å†…å®¹çš„JSONå­—ç¬¦ä¸²"""
    try:
        # å°è¯•ç›´æ¥è§£ææ•´ä¸ªå“åº”
        return json.loads(response_text)
    except json.JSONDecodeError:
        try:
            # å°è¯•æå–JSONéƒ¨åˆ†
            start_idx = response_text.find('{')
            end_idx = response_text.rfind('}') + 1
            if start_idx != -1 and end_idx != 0:
                json_str = response_text[start_idx:end_idx]
                return json.loads(json_str)
        except:
            pass

    # å°è¯•æå–JSONä»£ç å—
    try:
        if "```json" in response_text:
            json_str = response_text.split("```json")[1].split("```")[0].strip()
            return json.loads(json_str)
    except:
        pass

    # å°è¯•ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–JSON
    try:
        json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
        if json_match:
            return json.loads(json_match.group(0))
    except:
        pass

    return None


# æ•°æ®æ¡†ä»£ç† - å¤„ç†CSV/Excelæ–‡ä»¶
def dataframe_agent(df, query):
    try:
        # ä½¿ç”¨æç¤ºè¯æ¨¡æ¿
        structured_prompt = DF_AGENT_PROMPT_TEMPLATE.format(
            df_head=df.head(3).to_string(),
            query=query
        )

        # åˆ›å»ºä»£ç† - æ˜¾å¼è®¾ç½®å“åº”ç¼–ç 
        agent = create_pandas_dataframe_agent(
            ChatOpenAI(
                api_key=st.session_state.API_KEY,
                base_url='https://twapi.openai-hk.com/v1',
                model=st.session_state.selected_model,
                temperature=0.2,
                max_tokens=st.session_state.model_max_length,
                model_kwargs={'response_format': {'type': 'text'}}  # ç¡®ä¿å“åº”æ˜¯æ–‡æœ¬æ ¼å¼
            ),
            df,
            verbose=True,
            handle_parsing_errors=lambda _: "è¯·æŒ‰æŒ‡å®šæ ¼å¼å›å¤",
            max_iterations=3,
            allow_dangerous_code=True,
            include_df_in_prompt=True
        )

        # è·å–ä»£ç†å“åº”å¹¶æ˜¾å¼è§£ç ä¸ºUTF-8
        response = agent.invoke(structured_prompt)['output']

        # æ˜¾å¼ç¼–ç ä¸ºUTF-8
        if isinstance(response, str):
            response = response.encode('utf-8', 'ignore').decode('utf-8')

        # è°ƒè¯•ä¿¡æ¯
        st.toast(f"ä»£ç†åŸå§‹å“åº”é•¿åº¦: {len(response)} å­—ç¬¦")

        # å°è¯•è§£æä¸ºç»“æ„åŒ–æ•°æ®
        parsed_response = safe_json_parse(response)
        if parsed_response:
            return parsed_response

        # ä¿®å¤ï¼šå¢å¼ºå¤šè¡Œæ–‡æœ¬å¤„ç†èƒ½åŠ›
        # 1. æ£€æŸ¥æ˜¯å¦åŒ…å«å¤šè¡Œæ•°æ®ï¼ˆå¦‚æ¯æœˆé”€å”®é¢ï¼‰
        if re.search(r'(æœˆ|æœˆä»½|month).*[\d,]+', response, re.IGNORECASE):
            # æå–æ‰€æœ‰æœˆä»½æ•°æ®è¡Œ
            lines = [line.strip() for line in response.split('\n') if re.search(r'[\d,]+', line)]

            # æ ¼å¼åŒ–ä¸ºæ›´æ˜“è¯»çš„å½¢å¼
            formatted_response = "æ¯æœˆé”€å”®é¢ç»Ÿè®¡ï¼š\n" + "\n".join(lines)
            return {"answer": formatted_response}

        # 2. æ£€æŸ¥æ˜¯å¦æ˜¯å•ä¸ªæ•°å€¼ç­”æ¡ˆ
        if re.search(r'[\d,.]+', response):
            # æå–æ•°å€¼å’Œå•ä½
            match = re.search(r'([\d,.]+)(.*)', response)
            if match:
                value = match.group(1).replace(',', '')
                unit = match.group(2).strip()
                return {"answer": f"{value}{unit}"}

        # 3. å¦‚æœæ˜¯æ™®é€šæ–‡æœ¬ï¼Œç›´æ¥è¿”å›
        return {"answer": response}

    except Exception as e:
        st.error(f"æ•°æ®åˆ†æå‡ºé”™ï¼š{e}")
        return {
            "error": str(e),
            "answer": "ç³»ç»Ÿå¤„ç†æ•°æ®æ—¶å‡ºé”™"
        }

# RAGä»£ç† - å¤„ç†TXTæ–‡ä»¶
def rag_agent(query):
    try:
        # åŠ è½½åµŒå…¥æ¨¡å‹
        if 'em_model' not in st.session_state:
            try:
                # ä½¿ç”¨æ­£ç¡®çš„ BGE ä¸­æ–‡æ¨¡å‹
                model_name = "BAAI/bge-small-zh-v1.5"
                st.session_state.em_model = HuggingFaceBgeEmbeddings(
                    model_name=model_name,
                    encode_kwargs={'normalize_embeddings': True}  # é‡è¦å‚æ•°
                )
            except Exception as e:
                st.error(f"åŠ è½½åµŒå…¥æ¨¡å‹å¤±è´¥ï¼š{e}")
                return {"answer": "æ— æ³•åŠ è½½æ–‡æœ¬å¤„ç†æ¨¡å‹ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥"}

        # å¦‚æœæ˜¯æ–°æ–‡ä»¶ï¼Œå¤„ç†æ–‡æœ¬
        if st.session_state.is_new_file:
            with open(f'{st.session_state.session_id}.txt', 'w', encoding='utf-8') as f:
                f.write(st.session_state.txt_content)

            loader = TextLoader(f'{st.session_state.session_id}.txt', encoding='utf-8')
            docs = loader.load()

            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=1000,
                chunk_overlap=50,
                separators=["\n", "ã€‚", "ï¼", "ï¼Ÿ", "ï¼Œ", "ã€", ""]
            )
            texts = text_splitter.split_documents(docs)

            db = FAISS.from_documents(texts, st.session_state.em_model)
            st.session_state.db = db
            st.session_state.is_new_file = False

        # åˆ›å»ºæ£€ç´¢é“¾
        model = ChatOpenAI(
            api_key=st.session_state.API_KEY,
            base_url='https://twapi.openai-hk.com/v1',
            model=st.session_state.selected_model,
            temperature=st.session_state.model_temperature,
            max_tokens=st.session_state.model_max_length
        )

        retriever = st.session_state.db.as_retriever()

        # æ˜¾å¼åŠ è½½èŠå¤©å†å²
        chat_history = st.session_state.memory.load_memory_variables({})["history"]

        chain = ConversationalRetrievalChain.from_llm(
            llm=model,
            retriever=retriever,
            return_source_documents=True
        )

        # ä¼ é€’ chat_history å‚æ•°
        result = chain.invoke({
            "question": query,
            "chat_history": chat_history
        })

        return {"answer": result['answer']}
    except Exception as e:
        st.error(f"æ–‡æœ¬å¤„ç†å‡ºé”™ï¼š{e}")
        return {"answer": "æ— æ³•å¤„ç†æ–‡æœ¬å†…å®¹ï¼Œè¯·é‡è¯•æˆ–ä¸Šä¼ å…¶ä»–æ–‡ä»¶ã€‚"}

# ä¸»åº”ç”¨
def main():
    # è®¾ç½®é¡µé¢é…ç½®ï¼ˆç¡®ä¿ä¸­æ–‡å­—ç¬¦æ”¯æŒï¼‰
    st.set_page_config(
        page_title="SuperAI æ™ºèƒ½åˆ†æåŠ©æ‰‹",
        page_icon="ğŸš€",
        layout="wide",
        initial_sidebar_state="expanded"
    )

    init_session_state()

    # é¡µé¢æ ‡é¢˜
    header_container = st.container()
    with header_container:
        cols = st.columns([1, 8, 1])
        with cols[1]:
            st.markdown("""
                <div style="text-align:center; margin-bottom:40px">
                    <h1 style="margin-bottom:0">SuperAI æ™ºèƒ½åˆ†æåŠ©æ‰‹ğŸš€</h1>
                    <p style="color:#6C63FF; font-size:1.2rem">æ•°æ®æ´å¯Ÿä»æœªå¦‚æ­¤ç®€å•</p>
                </div>
            """, unsafe_allow_html=True)

    # ä¾§è¾¹æ 
    with st.sidebar:
        st.title("è¶…çº§æ™ºèƒ½åˆ†æåŠ©æ‰‹")
        api_key = st.text_input('è¯·è¾“å…¥OpenAI API Key', type='password', value=st.session_state.API_KEY)
        if api_key:
            st.session_state.API_KEY = api_key

        if st.button("ğŸ”„ æ–°å»ºä¼šè¯", use_container_width=True):
            # ä¿å­˜å½“å‰ä¼šè¯åˆ°å†å²ä¼šè¯
            if len(st.session_state.current_session_messages) > 1:  # é¿å…ä¿å­˜åªæœ‰æ¬¢è¿æ¶ˆæ¯çš„ä¼šè¯
                new_session = {
                    'id': uuid.uuid4().hex,
                    'messages': st.session_state.current_session_messages.copy(),
                    'timestamp': time.strftime("%Y-%m-%d %H:%M", time.localtime())
                }
                st.session_state.history_sessions.append(new_session)

            # é‡ç½®å½“å‰ä¼šè¯
            st.session_state.current_session_messages = [
                {'role': 'ai', 'content': 'ä½ å¥½ï¼Œæˆ‘æ˜¯ä½ çš„AIåŠ©æ‰‹ï¼Œè¯·é—®æœ‰ä»€ä¹ˆèƒ½å¸®åŠ©ä½ å—ï¼Ÿ'}]
            st.session_state.memory = ConversationBufferMemory(return_messages=True)
            st.session_state.viewing_history = False
            st.session_state.df = None
            st.session_state.txt_content = None
            st.session_state.is_new_file = True
            st.session_state.session_id = uuid.uuid4().hex
            # æ–°å¢ï¼šæ¸…é™¤æ–‡ä»¶ä¸Šä¼ å™¨çŠ¶æ€
            st.session_state.file_uploader_key = str(uuid.uuid4())  # ç”Ÿæˆæ–°çš„éšæœºé”®
            # é‡ç½®æ¨¡å¼å’Œå·¥ä½œè¡¨é€‰æ‹©
            st.session_state.current_mode = "ğŸ’¬ èŠå¤©å¯¹è¯"
            st.session_state.selected_sheet = None
            st.rerun()

        st.divider()

        # å†å²ä¼šè¯
        st.subheader("ğŸ“œ å†å²ä¼šè¯")
        if st.session_state.history_sessions:
            for i, session in enumerate(st.session_state.history_sessions):
                # æŸ¥æ‰¾ç¬¬ä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ä½œä¸ºé¢„è§ˆ
                user_preview = ""
                for msg in session['messages']:
                    if msg['role'] == 'human':
                        user_preview = msg['content'][:30] + ('...' if len(msg['content']) > 30 else '')
                        break

                st.caption(f"ğŸ“… {session['timestamp']}")
                st.caption(f"ğŸ—£ï¸ ç”¨æˆ·: {user_preview}")

                col1, col2 = st.columns([3, 1])
                with col1:
                    if st.button(f"æŸ¥çœ‹ä¼šè¯ {i + 1}", key=f"view_{i}", use_container_width=True):
                        st.session_state.viewing_history = True
                        st.session_state.current_session_index = i
                with col2:
                    if st.button("âŒ", key=f"delete_{i}", use_container_width=True):
                        del st.session_state.history_sessions[i]
                        st.rerun()
                st.divider()
        else:
            st.caption("æš‚æ— å†å²ä¼šè¯")
        st.divider()

        # æ¨¡å‹é…ç½®
        st.subheader("âš™ï¸ æ¨¡å‹é…ç½®")
        st.session_state.selected_model = st.selectbox(
            "é€‰æ‹©AIæ¨¡å‹",
            ["gpt-4o", "gpt-4o-mini", "gpt-4", "gpt-3.5-turbo"],
            index=1,
            help="é€‰æ‹©è¦ä½¿ç”¨çš„AIæ¨¡å‹"
        )

        st.session_state.model_temperature = st.slider(
            "æ¸©åº¦ (Temperature)",
            0.0, 1.0, 0.7, 0.1,
            help="æ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„éšæœºæ€§ï¼Œå€¼è¶Šé«˜è¶Šæœ‰åˆ›æ„ï¼Œå€¼è¶Šä½è¶Šç¨³å®š"
        )

        st.session_state.model_max_length = st.slider(
            "æœ€å¤§ç”Ÿæˆé•¿åº¦",
            100, 4000, 1000, 100,
            help="é™åˆ¶AIç”Ÿæˆçš„æœ€å¤§tokenæ•°é‡"
        )

        st.session_state.system_prompt = st.text_area(
            "ç³»ç»Ÿæç¤ºè¯",
            # ä½¿ç”¨æç¤ºè¯
            RAG_AGENT_PROMPT_TEMPLATE,
            help="æŒ‡å¯¼AIå¦‚ä½•å›ç­”é—®é¢˜çš„ç³»ç»Ÿçº§æç¤º"
        )

    # æŸ¥çœ‹å†å²ä¼šè¯
    if st.session_state.viewing_history and st.session_state.current_session_index is not None:
        st.subheader("ğŸ“œ å†å²æ¶ˆæ¯")
        session = st.session_state.history_sessions[st.session_state.current_session_index]

        for message in session['messages']:
            with st.chat_message("user" if message["role"] == "human" else "assistant"):
                st.write(message["content"])

        if st.button("â†©ï¸ è¿”å›å½“å‰å¯¹è¯", use_container_width=True):
            st.session_state.viewing_history = False
            st.rerun()

    # ä¸»ç•Œé¢ - æ–‡ä»¶ä¸Šä¼ å’ŒèŠå¤©
    else:
        # æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
        st.subheader("ğŸ“¤ ä¸Šä¼ æ•°æ®æ–‡ä»¶")
        file = st.file_uploader(
            "ä¸Šä¼ CSVã€Excelæˆ–TXTæ–‡ä»¶",
            type=["csv", "xlsx", "txt"],
            label_visibility="collapsed",
            key=st.session_state.get('file_uploader_key', 'default_file_uploader')
        )

        # å¤„ç†æ–‡ä»¶ä¸Šä¼  - ä½¿ç”¨ä»app.pyæ·»åŠ çš„process_uploaded_fileå‡½æ•°
        if file:
            process_uploaded_file(file)

        # æ˜¾ç¤ºå½“å‰æ¨¡å¼ (ä»app.pyæ·»åŠ )
        if 'current_mode' in st.session_state:
            st.markdown(f"**å½“å‰æ¨¡å¼**: {st.session_state.current_mode}")

        # é‡ç½®æ–‡ä»¶çŠ¶æ€é€»è¾‘
        if file is None and (st.session_state.df is not None or st.session_state.txt_content is not None):
            # ç”¨æˆ·å·²åˆ é™¤æ–‡ä»¶ï¼Œé‡ç½®ç›¸å…³çŠ¶æ€
            st.session_state.df = None
            st.session_state.txt_content = None
            st.session_state.is_new_file = True
            st.toast("æ–‡ä»¶å·²ç§»é™¤ï¼Œç°åœ¨å¯è¿›è¡Œæ–‡æœ¬é—®ç­”")
            # æ¸…é™¤é¢„è§ˆåŒºåŸŸ
            st.rerun()
        elif file:
            # å¤„ç†æ–‡ä»¶ä¸Šä¼ åæ˜¾ç¤ºé¢„è§ˆ
            try:
                file_type = file.name.split('.')[-1].lower()
                if file_type in ['csv', 'xlsx'] and st.session_state.df is not None:
                    with st.expander("ğŸ‘€ æ•°æ®é¢„è§ˆ", expanded=True):
                        st.dataframe(st.session_state.df.head(10), use_container_width=True)
                        st.caption(f"æ•°æ®ç»´åº¦: {st.session_state.df.shape[0]} è¡Œ Ã— {st.session_state.df.shape[1]} åˆ—")
                elif file_type == 'txt' and st.session_state.txt_content is not None:
                    with st.expander("ğŸ“ æ–‡æœ¬å†…å®¹é¢„è§ˆ", expanded=True):
                        st.text_area("", st.session_state.txt_content, height=300, label_visibility="collapsed")
            except Exception as e:
                st.error(f"æ–‡ä»¶é¢„è§ˆé”™è¯¯: {str(e)}")

        # æ˜¾ç¤ºå½“å‰ä¼šè¯èŠå¤©å†å²
        for message in st.session_state.current_session_messages:
            with st.chat_message("user" if message["role"] == "human" else "assistant"):
                st.write(message["content"])

        # ç”¨æˆ·è¾“å…¥
        if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...", key="user_input"):
            if not st.session_state.API_KEY:
                st.error('ğŸ”‘ è¯·è¾“å…¥OpenAI API Key')
                st.stop()

            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å½“å‰ä¼šè¯
            st.session_state.current_session_messages.append({'role': 'human', 'content': prompt})

            with st.chat_message("user"):
                st.write(prompt)

            # AIå¤„ç†åŒºåŸŸ
            with st.spinner('ğŸ¤– AIæ­£åœ¨æ€è€ƒï¼Œè¯·ç¨ç­‰...'):
                try:
                    # æ ¹æ®æ–‡ä»¶ç±»å‹é€‰æ‹©å¤„ç†æ–¹å¼
                    if st.session_state.df is not None:
                        response = dataframe_agent(st.session_state.df, prompt)
                    elif st.session_state.txt_content is not None:
                        response = rag_agent(prompt)
                    else:
                        # æ²¡æœ‰æ–‡ä»¶æ—¶ä½¿ç”¨æ–‡æœ¬ä»£ç†
                        response = {"answer": text_agent(prompt)}

                    # ç¡®ä¿responseæ˜¯å­—å…¸ç±»å‹
                    if not isinstance(response, dict):
                        response = {"answer": str(response)}

                    # å¤„ç†é”™è¯¯å“åº”
                    if "error" in response:
                        st.error(f"é”™è¯¯: {response['error']}")
                        ai_response = response.get("answer", "æ•°æ®åˆ†æå¤±è´¥")
                    else:
                        # æå–æ–‡æœ¬å›ç­”
                        ai_response = response.get("answer", "æ²¡æœ‰è·å–åˆ°å›ç­”å†…å®¹")

                        # ç§»é™¤ä¸éœ€è¦çš„æ–‡æœ¬
                        unwanted_phrases = [
                            "è¯¦ç»†çš„æ–‡æœ¬è§£é‡Šå’Œç»Ÿè®¡ç»“æœ:",
                            "è¯¦ç»†çš„æ–‡æœ¬è§£é‡Šå’Œç»Ÿè®¡ç»“æœï¼š",
                            "è¯¦ç»†çš„æ–‡æœ¬è§£é‡Šå’Œç»Ÿè®¡ç»“æœ:",
                            "è¯¦ç»†è§£é‡Šå’Œç»Ÿè®¡ç»“æœ:",
                            "ğŸ¤–"
                        ]

                        for phrase in unwanted_phrases:
                            ai_response = ai_response.replace(phrase, "").strip()

                        # å›¾è¡¨å…³é”®è¯åˆ—è¡¨
                        chart_keywords = ["å›¾è¡¨", "æŸ±çŠ¶å›¾", "æŠ˜çº¿å›¾", "é¥¼å›¾", "å¯è§†åŒ–", "å±•ç¤ºå›¾", "æ•£ç‚¹å›¾", "ç®±çº¿å›¾",
                                          "ç›´æ–¹å›¾", "é¢ç§¯å›¾"]

                        # åªåœ¨ç”¨æˆ·æ˜ç¡®è¦æ±‚å›¾è¡¨ä¸”responseæ˜¯å­—å…¸æ—¶æ‰æ£€æŸ¥
                        if isinstance(response, dict) and "charts" in response:
                            if any(kw in prompt.lower() for kw in chart_keywords):
                                # === æ–°å¢ï¼šè¾“å‡ºå›¾è¡¨æ ‡é¢˜å’Œç±»å‹ ===
                                st.subheader("ğŸ“ˆ å›¾è¡¨ä¿¡æ¯")
                                st.markdown(f"**å›¾è¡¨ç±»å‹**: {response['charts'][0]['type']}")
                                st.markdown(f"**å›¾è¡¨æ ‡é¢˜**: {response['charts'][0].get('title', 'æ— æ ‡é¢˜')}")

                                for chart in response["charts"]:
                                    if "type" in chart and "data" in chart:
                                        create_chart(chart["data"], chart["type"])
                        else:
                            # ç§»é™¤å¯èƒ½çš„å›¾è¡¨ç”Ÿæˆæ¶ˆæ¯
                            ai_response = ai_response.split("\n\nå·²ç”Ÿæˆ")[0]

                    # æ·»åŠ AIå“åº”åˆ°å½“å‰ä¼šè¯
                    st.session_state.current_session_messages.append({'role': 'ai', 'content': ai_response})

                    # æ˜¾ç¤ºAIå“åº”
                    with st.chat_message("assistant"):
                        if "error" in response:
                            st.error(ai_response)
                        else:
                            st.write(ai_response)
                except Exception as e:
                    error_msg = f"å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {str(e)}"
                    st.session_state.current_session_messages.append({'role': 'ai', 'content': error_msg})
                    with st.chat_message("assistant"):
                        st.error(error_msg)


if __name__ == "__main__":
    main()